{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8243361,"sourceType":"datasetVersion","datasetId":4890247}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport argparse\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,GlobalMaxPool2D,BatchNormalization,Dropout\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.status.busy":"2024-04-29T07:24:16.410702Z","iopub.execute_input":"2024-04-29T07:24:16.411060Z","iopub.status.idle":"2024-04-29T07:24:20.656567Z","shell.execute_reply.started":"2024-04-29T07:24:16.411032Z","shell.execute_reply":"2024-04-29T07:24:20.655794Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-29 07:24:17.641340: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 07:24:17.641395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 07:24:17.642819: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"nrem_sample = np.load('/kaggle/input/sleep-state-classification/nrem_sample.npy')\nwakefulness_sample =  np.load('/kaggle/input/sleep-state-classification/wakefulness_sample.npy')\nrem_sample = np.load('/kaggle/input/sleep-state-classification/rem_sample.npy')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T07:24:33.713149Z","iopub.execute_input":"2024-04-29T07:24:33.713999Z","iopub.status.idle":"2024-04-29T07:24:34.040598Z","shell.execute_reply.started":"2024-04-29T07:24:33.713966Z","shell.execute_reply":"2024-04-29T07:24:34.039826Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"nrem_sample = np.load('/kaggle/input/sleep-state-classification/nrem_sample.npy')\nwakefulness_sample =  np.load('/kaggle/input/sleep-state-classification/wakefulness_sample.npy')\nrem_sample ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"def focal_loss(gamma=3.0, alpha=0.3):\n    def focal_loss_fixed(y_true, y_pred):\n        epsilon = 1e-9\n        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n\n        # Compute cross entropy\n        cross_entropy = -y_true * tf.math.log(y_pred)\n\n        # Compute focal loss\n        focal_loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n\n        # Sum over classes\n        return tf.reduce_sum(focal_loss, axis=-1)\n    \n    return focal_loss_fixed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2D CNN algorithm","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n\n# Create labels: Wakefulness=0, NREM=1, REM=2\nX = np.concatenate([wakefulness_sample, nrem_sample, rem_sample])\ny = np.array([0]*len(wakefulness_sample) + [1]*len(nrem_sample) + [2]*len(rem_sample))\n\n# Normalize data\nX = X.astype('float32') / 255.0  # Adjust based on your actual data range\n\n# One-hot encode labels\ny = to_categorical(y)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n# Compute class weights for balancing the data\nclass_weights = compute_class_weight('balanced', classes=np.unique(np.argmax(y, axis=1)), y=np.argmax(y, axis=1))\nclass_weight_dict = dict(enumerate(class_weights))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Define the CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(3, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss=focal_loss(), metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model with class weights\nhistory = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), class_weight=class_weight_dict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate model performance\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f'Test Accuracy: {test_acc * 100:.2f}%')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\ny_true_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class labels\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_true_classes, y_pred_classes)\n\n# Compute the accuracy\naccuracy = accuracy_score(y_true_classes, y_pred_classes)\n\n# Print the classification report\nprint(\"Classification Report:\\n\", classification_report(y_true_classes, y_pred_classes))\n\n# Displaying the confusion matrix using seaborn\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NREM', 'REM', 'Wakefulness'], yticklabels=['NREM', 'REM', 'Wakefulness'])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Print accuracy\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG19 algorithm","metadata":{}},{"cell_type":"code","source":"# Create labels\nnrem_labels = np.zeros(len(nrem_sample))\nrem_labels = np.ones(len(rem_sample))\nwakefulness_labels = np.full(len(wakefulness_sample), 2)\n\n# Combine data\nX = np.concatenate((nrem_sample, rem_sample, wakefulness_sample), axis=0)\ny = np.concatenate((nrem_labels, rem_labels, wakefulness_labels), axis=0)\n\n# One-hot encode labels\ny = to_categorical(y, num_classes=3)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Input\n\n\ndef build_custom_vgg19(input_shape=(36, 168, 168)):\n    # Create a VGG-like model for 36 input channels\n    input_tensor = Input(shape=input_shape)\n    x = BatchNormalization()(input_tensor)  # Normalize the input\n    # Add VGG19 layers, initialized without weights\n    base_model = VGG19(include_top=False, weights=None, input_tensor=x)\n\n    # Customize the training of the initial layers or leave them trainable\n    for layer in base_model.layers[:17]:\n        layer.trainable = False\n\n    x = base_model.output\n    x = GlobalMaxPool2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(3, activation='softmax')(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    return model\n\n# Instantiate and compile the model\nmodel = build_custom_vgg19()\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss=focal_loss(), metrics=['accuracy'])\n\n# Assuming X_train, y_train, X_test, y_test are correctly shaped and split\nmodel.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the test set\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\n\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\ny_true_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class labels\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_true_classes, y_pred_classes)\n\n# Compute the accuracy\naccuracy = accuracy_score(y_true_classes, y_pred_classes)\n\n# Print the classification report\nprint(\"Classification Report:\\n\", classification_report(y_true_classes, y_pred_classes))\n\n# Displaying the confusion matrix using seaborn\nplt.figure(figsize=(10, 7))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NREM', 'REM', 'Wakefulness'], yticklabels=['NREM', 'REM', 'Wakefulness'])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Print accuracy\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","metadata":{},"execution_count":null,"outputs":[]}]}